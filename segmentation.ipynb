{"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import wordDetector"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3f369ae-74ca-4d43-8045-0b43575aec39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=2.0, threshold=0):\n","    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n","    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n","    sharpened = float(amount + 1) * image - float(amount) * blurred\n","    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n","    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n","    sharpened = sharpened.round().astype(np.uint8)\n","    if threshold > 0:\n","        low_contrast_mask = np.absolute(image - blurred) < threshold\n","        np.copyto(sharpened, image, where=low_contrast_mask)\n","    return sharpened\n","\n","def preprocessImage(image):\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    lower = np.array([0,0,0])\n","    upper = np.array([179, 255, 209])\n","    mask = cv2.inRange(image, lower, upper)\n","    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2,2))\n","    close = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n","    image[close==0] = (255,255,255)\n","    retouch_mask = (image <= [250.,250.,250.]).all(axis=2)\n","    image[retouch_mask] = [0,0,0]\n","    image = 255-image\n","    return image[...,0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1916ec1f-5dd5-41f0-8295-6e41d47b26a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"IAM","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4743876}},"nbformat":4,"nbformat_minor":0}